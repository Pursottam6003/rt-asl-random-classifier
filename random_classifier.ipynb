{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for data processing\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# media pipe hands object\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False, min_detection_confidence=0.9, min_tracking_confidence=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create image with landmarks\n",
    "def get_hand_landmarks_image(frame):\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = hands.process(image_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing.DrawingSpec(color=(20,20,20), thickness=2, circle_radius=2),\n",
    "                connection_drawing_spec=mp_drawing.DrawingSpec(color=(20,20,20), thickness=2, circle_radius=2),\n",
    "            )\n",
    "    return bool(results.multi_hand_landmarks), frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data dir paths\n",
    "unprocessed_data_dir = 'new_unprocessed_data'\n",
    "processed_data_dir = 'new_unprocessed_data/new_unprocessed'\n",
    "test_data_dir = 'new_unprocessed_data/test_unprocessed_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing images for A...sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\0.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\1.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\2.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\3.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\4.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\5.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\6.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\7.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\8.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\9.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\10.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\11.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\12.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\13.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\14.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\15.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\16.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\17.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\18.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\19.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\20.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\21.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\22.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\23.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\24.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\25.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\26.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\27.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\28.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\29.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\30.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\31.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\32.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\33.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\34.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\35.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\36.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\37.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\38.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\39.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\40.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\41.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\42.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\43.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\44.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\45.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\46.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\47.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\48.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\49.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\50.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\51.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\52.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\53.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\54.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\55.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\56.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\57.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\58.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\59.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\60.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\61.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\62.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\63.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\64.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\65.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\66.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\67.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\68.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\69.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\70.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\71.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\72.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\73.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\74.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\75.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\76.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\77.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\78.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\79.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\80.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\81.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\82.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\83.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\84.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\85.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\86.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\87.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\88.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\89.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\90.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\91.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\92.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\93.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\94.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\95.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\96.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\97.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\98.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\99.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\100.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\101.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\102.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\103.jpg\n",
      "sucess\n",
      "new_unprocessed_data/new_unprocessed\\0\\104.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m curr_img \u001b[38;5;241m<\u001b[39m n_images_per_class:\n\u001b[0;32m     15\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 16\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;66;03m# Preprocess the frame to match the input size of the model and scale the pixel values\u001b[39;00m\n\u001b[0;32m     19\u001b[0m         frame \u001b[38;5;241m=\u001b[39m frame[:, \u001b[38;5;241m80\u001b[39m:\u001b[38;5;241m560\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# function for preprocessing images\n",
    "img_processing_func = get_hand_landmarks_image\n",
    "# create dataset for ASL characters A-Z and blank\n",
    "\n",
    "class_labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'blank']\n",
    "n_images_per_class = 333\n",
    "\n",
    "for index, label in enumerate(class_labels):\n",
    "    # os.makedirs(os.path.join(processed_data_dir, str(index)), exist_ok=True)\n",
    "    curr_img = 0\n",
    "    print(f\"Capturing images for {label}...\", end='')\n",
    "    while curr_img < n_images_per_class:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.waitKey(200)\n",
    "        if ret:\n",
    "            # Preprocess the frame to match the input size of the model and scale the pixel values\n",
    "            frame = frame[:, 80:560]\n",
    "            frame = cv2.resize(frame, (224, 224))\n",
    "\n",
    "            # get hand landmarks image with mediapipe\n",
    "            success, hand_landmarks_img = img_processing_func(frame)\n",
    "\n",
    "            frame_label = f'Finished {label}. press space' if curr_img == n_images_per_class else f'{label} {curr_img}/{n_images_per_class-1}' \n",
    "            cv2.putText(hand_landmarks_img, frame_label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 200), 2, cv2.LINE_AA)\n",
    "            cv2.imshow('Preview', hand_landmarks_img)\n",
    "            \n",
    "            # save image\n",
    "            if success:\n",
    "                print('sucess')\n",
    "                print(os.path.join(processed_data_dir, str(index), f'{curr_img}.jpg'))\n",
    "                cv2.imwrite(os.path.join(processed_data_dir, str(index), f'{curr_img}.jpg'), frame)\n",
    "                curr_img += 1\n",
    "\n",
    "                if curr_img == n_images_per_class:\n",
    "                    print(\"Done!\")\n",
    "                    while True:\n",
    "                        if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "                            break\n",
    "                \n",
    "                # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                #     break\n",
    "                # cv2.waitKey(200)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing images for A..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Final_Project\\rt-asl-translation-cnn\\myenv\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m curr_img \u001b[38;5;241m<\u001b[39m n_images_per_class:\n\u001b[0;32m     16\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;66;03m# Preprocess the frame to match the input size of the model and scale the pixel values\u001b[39;00m\n\u001b[0;32m     20\u001b[0m         frame \u001b[38;5;241m=\u001b[39m frame[:, \u001b[38;5;241m80\u001b[39m:\u001b[38;5;241m560\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# function for preprocessing images\n",
    "img_processing_func = get_hand_landmarks_image\n",
    "# create dataset for ASL characters A-Z and blank\n",
    "\n",
    "class_labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'blank']\n",
    "n_images_per_class = 334\n",
    "processed_data_dir = \"dataDir\"  # replace with your directory path\n",
    "\n",
    "for index, label in enumerate(class_labels):\n",
    "    os.makedirs(os.path.join(processed_data_dir, str(index)), exist_ok=True)\n",
    "    curr_img = 0\n",
    "    print(f\"Capturing images for {label}...\", end='')\n",
    "    while curr_img < n_images_per_class:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.waitKey(200)\n",
    "        if ret:\n",
    "            # Preprocess the frame to match the input size of the model and scale the pixel values\n",
    "            frame = frame[:, 80:560]\n",
    "            frame = cv2.resize(frame, (224, 224))\n",
    "\n",
    "            # get hand landmarks image with mediapipe\n",
    "\n",
    "            # raw image \n",
    "            raw_img = frame.copy()\n",
    "            success, hand_landmarks_img = img_processing_func(frame)\n",
    "\n",
    "            frame_label = f'Finished {label}. press space' if curr_img == n_images_per_class else f'{label} {curr_img}/{n_images_per_class-1}' \n",
    "            cv2.putText(hand_landmarks_img, frame_label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 200), 2, cv2.LINE_AA)\n",
    "            cv2.imshow('Preview', hand_landmarks_img)\n",
    "            \n",
    "            # save image\n",
    "            if success:\n",
    "                cv2.imwrite(os.path.join(processed_data_dir, str(index), f'{curr_img}.jpg'), raw_img)\n",
    "                curr_img += 1\n",
    "\n",
    "                if curr_img == n_images_per_class:\n",
    "                    print(\"Done!\")\n",
    "                    while True:\n",
    "                        if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "                            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Final_Project\\rt-asl-translation-cnn\\myenv\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0.jpg\n",
      "Processed 1.jpg\n",
      "Processed 10.jpg\n",
      "Processed 11.jpg\n",
      "Processed 12.jpg\n",
      "Processed 13.jpg\n",
      "Processed 14.jpg\n",
      "Processed 15.jpg\n",
      "Processed 16.jpg\n",
      "Processed 17.jpg\n",
      "Processed 18.jpg\n",
      "Processed 19.jpg\n",
      "Processed 2.jpg\n",
      "Processed 20.jpg\n",
      "Processed 21.jpg\n",
      "Processed 22.jpg\n",
      "Processed 23.jpg\n",
      "Processed 24.jpg\n",
      "Processed 25.jpg\n",
      "Processed 26.jpg\n",
      "Processed 27.jpg\n",
      "Processed 28.jpg\n",
      "Processed 29.jpg\n",
      "Processed 3.jpg\n",
      "Processed 30.jpg\n",
      "Processed 31.jpg\n",
      "Processed 32.jpg\n",
      "Processed 33.jpg\n",
      "Processed 34.jpg\n",
      "Processed 35.jpg\n",
      "Processed 36.jpg\n",
      "Processed 37.jpg\n",
      "Processed 38.jpg\n",
      "Processed 39.jpg\n",
      "Processed 4.jpg\n",
      "Processed 40.jpg\n",
      "Processed 41.jpg\n",
      "Processed 42.jpg\n",
      "Processed 43.jpg\n",
      "Processed 44.jpg\n",
      "Processed 45.jpg\n",
      "Processed 46.jpg\n",
      "Processed 47.jpg\n",
      "Processed 48.jpg\n",
      "Processed 49.jpg\n",
      "Processed 5.jpg\n",
      "Processed 50.jpg\n",
      "Processed 51.jpg\n",
      "Processed 52.jpg\n",
      "Processed 53.jpg\n",
      "Processed 54.jpg\n",
      "Processed 55.jpg\n",
      "Processed 56.jpg\n",
      "Processed 57.jpg\n",
      "Processed 58.jpg\n",
      "Processed 59.jpg\n",
      "Processed 6.jpg\n",
      "Processed 60.jpg\n",
      "Processed 61.jpg\n",
      "Processed 62.jpg\n",
      "Processed 63.jpg\n",
      "Processed 64.jpg\n",
      "Processed 65.jpg\n",
      "Processed 66.jpg\n",
      "Processed 67.jpg\n",
      "Processed 68.jpg\n",
      "Processed 69.jpg\n",
      "Processed 7.jpg\n",
      "Processed 70.jpg\n",
      "Processed 71.jpg\n",
      "Processed 72.jpg\n",
      "Processed 73.jpg\n",
      "Processed 74.jpg\n",
      "Processed 75.jpg\n",
      "Processed 76.jpg\n",
      "Processed 77.jpg\n",
      "Processed 78.jpg\n",
      "Processed 79.jpg\n",
      "Processed 8.jpg\n",
      "Processed 80.jpg\n",
      "Processed 81.jpg\n",
      "Processed 82.jpg\n",
      "Processed 83.jpg\n",
      "Processed 84.jpg\n",
      "Processed 85.jpg\n",
      "Processed 86.jpg\n",
      "Processed 9.jpg\n"
     ]
    }
   ],
   "source": [
    "# get landmak points for each image \n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.5)\n",
    "data_dir = \"./dataDir\"\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for dir_ in os.listdir(data_dir):\n",
    "    for img_path in os.listdir(os.path.join(data_dir, dir_)):\n",
    "        data_aux = []\n",
    "        img = cv2.imread(os.path.join(data_dir, dir_, img_path))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(img_rgb)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "                    data_aux.append(x)\n",
    "                    data_aux.append(y)\n",
    "            data.append(data_aux)\n",
    "            labels.append(dir_)\n",
    "            print(f\"Processed {img_path}\")\n",
    "file = open(\"processed.pickle\", \"wb\")\n",
    "pickle.dump({\"data\": data, \"labels\": labels}, file)\n",
    "file.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
